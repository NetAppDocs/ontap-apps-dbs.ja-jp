---
sidebar: sidebar 
permalink: oracle/oracle-asar2-storage-san-config-lun-placement.html 
keywords: SAN, ASM, LVM, oracle, LUN, ASA r2 
summary: ASA r2 を使用した Oracle およびONTAP LUN の配置 
searchtitle: ASA r2 を使用した Oracle データベース LUN の配置 
---
= LUNノハイチ
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
ASA r2 システム内でのデータベース LUN の最適な配置は、主にさまざまなONTAP機能がどのように使用されるかによって異なります。

ASA r2 システムでは、ストレージ ユニット (LUN または NVMe 名前空間) は、HA ペアのストレージの共通プールとして機能する、ストレージ可用性ゾーン (SAZ) と呼ばれる簡略化されたストレージ レイヤから作成されます。


NOTE: 通常、HA ペアごとにストレージの可用性ゾーン (SAZ) は 1 つだけあります。



== ストレージ可用性ゾーン (SAZ)

ASA r2 システムではボリュームは依然として存在しますが、ストレージ ユニットが作成されるときに自動的に作成されます。ストレージ ユニット (LUN または NVMe 名前空間) は、ストレージ可用性ゾーン (SAZ) に自動的に作成されたボリューム内で直接プロビジョニングされます。この設計により、手動でのボリューム管理が不要になり、Oracle データベースなどのブロック ワークロードのプロビジョニングがより直接的かつ合理的になります。



== SAZとストレージユニット

関連するストレージ ユニット (LUN または NVMe 名前空間) は通常、単一のストレージ可用性ゾーン (SAZ) 内に共存します。たとえば、10 個のストレージ ユニット (LUN) を必要とするデータベースでは、通常、簡潔さとパフォーマンスのために 10 個のユニットすべてを同じ SAZ に配置します。

[NOTE]
====
* ストレージ ユニットとボリュームの比率を 1:1 にする (つまり、ボリュームごとに 1 つのストレージ ユニット (LUN) を使用する) のが、 ASA r2 のデフォルトの動作です。
* ASA r2 システムに複数の HA ペアがある場合、特定のデータベースのストレージ ユニット (LUN) を複数の SAZ に分散して、コントローラの使用率とパフォーマンスを最適化できます。


====

NOTE: FC SAN のコンテキストでは、ここでのストレージ ユニットは LUN を指します。



== 整合性グループ（CG）、LUN、スナップショット

ASA r2 では、スナップショット ポリシーとスケジュールは、整合性グループ レベルで適用されます。整合性グループ レベルは、調整されたデータ保護のために複数の LUN または NVMe 名前空間をグループ化する論理構造です。10 個の LUN で構成されるデータセットでは、それらの LUN が同じ整合性グループの一部である場合、1 つのスナップショット ポリシーのみが必要になります。

整合性グループは、含まれるすべての LUN にわたってアトミック スナップショット操作を保証します。たとえば、10 個の LUN 上に存在するデータベース、または 10 個の異なる OS で構成される VMware ベースのアプリケーション環境は、基礎となる LUN が同じ整合性グループにグループ化されている場合、単一の一貫性のあるオブジェクトとして保護できます。異なる整合性グループに配置されている場合、スナップショットは、同時にスケジュールされていても、完全に同期されない可能性があります。

場合によっては、回復要件のために、関連する LUN セットを 2 つの異なる整合性グループに分割する必要があります。たとえば、データベースにはデータファイル用の LUN が 4 つ、ログ用の LUN が 2 つある場合があります。この場合、4 つの LUN を持つデータファイル整合性グループと 2 つの LUN を持つログ整合性グループが最適なオプションになる可能性があります。その理由は、独立した回復可能性です。データファイル整合性グループを以前の状態に選択的に復元できるため、4 つの LUN すべてがスナップショットの状態に戻されますが、重要なデータを含むログ整合性グループは影響を受けません。



== CG、LUN、 SnapMirror

SnapMirrorポリシーと操作は、スナップショット操作と同様に、LUN ではなく整合性グループで実行されます。

関連する LUN を単一の整合性グループ内に共存させることで、単一のSnapMirror関係を作成し、含まれるすべてのデータを 1 回の更新で更新できます。スナップショットと同様に、更新もアトミック操作になります。SnapMirrorデスティネーションには、ソース LUN の単一のポイントインタイムレプリカが存在することが保証されます。LUN が複数の整合性グループに分散されている場合、レプリカは相互に整合性がある場合とない場合があります。

[NOTE]
====
ASA r2 システムでのSnapMirrorレプリケーションには次の制限があります。

* SnapMirror同期レプリケーションはサポートされていません。
* SnapMirrorアクティブ同期は、2 つのASA r2 システム間でのみサポートされます。
* SnapMirror非同期レプリケーションは、2 つのASA r2 システム間でのみサポートされます。
* SnapMirror非同期レプリケーションは、 ASA r2 システムとASA、 AFF 、 FASシステムまたはクラウド間ではサポートされません。


詳細はこちら https://docs.netapp.com/us-en/asa-r2/data-protection/pre-defined-protection-policies.html["ASA r2 システムでサポートされるSnapMirrorレプリケーション ポリシー"]。

====


== CG、LUN、QoS

QoS は個々の LUN に選択的に適用できますが、通常は整合性グループ レベルで設定する方が簡単です。たとえば、特定のESXサーバ内のゲストが使用するすべての LUN を単一の整合性グループに配置し、 ONTAPアダプティブ QoS ポリシーを適用できます。その結果、すべての LUN に適用される、TiB あたりの IOPS 制限が自己スケーリングされます。

同様に、データベースが 100K IOPS を必要とし、10 個の LUN を占有している場合、各 LUN に 1 つずつ、10 個の個別の 10K IOPS 制限を設定するよりも、単一の整合性グループに 1 つの 100K IOPS 制限を設定する方が簡単です。



== 複数のCGレイアウト

LUN を複数の整合性グループに分散すると有益な場合があります。主な理由はコントローラのストライピングです。たとえば、HA ASA r2 ストレージ システムは、各コントローラの完全な処理およびキャッシュの能力が必要とされる単一の Oracle データベースをホストしている場合があります。この場合、一般的な設計では、LUN の半分をコントローラ 1 の単一の整合性グループに配置し、LUN の残り半分をコントローラ 2 の単一の整合性グループに配置します。

同様に、多数のデータベースをホストする環境では、LUN を複数の整合性グループに分散することで、コントローラーの使用率のバランスを確保できます。たとえば、それぞれ 10 個の LUN を持つ 100 個のデータベースをホストする HA システムでは、データベースごとにコントローラ 1 の整合性グループに 5 個の LUN を割り当て、コントローラ 2 の整合性グループに 5 個の LUN を割り当てることがあります。これにより、追加のデータベースがプロビジョニングされるときに対称的な読み込みが保証されます。

ただし、これらの例ではいずれも LUN と整合性グループの比率が 1:1 ではありません。目標は、関連する LUN を整合性グループに論理的にグループ化することで、管理性を最適化することです。

1:1 の LUN と整合性グループの比率が意味を成す例としては、コンテナ化されたワークロードが挙げられます。コンテナ化されたワークロードでは、各 LUN は実際には個別のスナップショットおよびレプリケーション ポリシーを必要とする単一のワークロードを表す可能性があり、そのため個別に管理する必要があります。このような場合、1:1 の比率が最適な場合があります。
